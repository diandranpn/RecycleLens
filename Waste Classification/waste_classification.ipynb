{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28c365c",
   "metadata": {},
   "source": [
    "# Data Preparation & Function Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf045f",
   "metadata": {},
   "source": [
    "### Setting Up Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf01423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"DATASET\")\n",
    "\n",
    "train_image_dir = data_path / \"TRAIN\"\n",
    "test_image_dir = data_path / \"TEST\"\n",
    "\n",
    "train_image_dir, test_image_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790947e8",
   "metadata": {},
   "source": [
    "### Visualize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for dirpath, dirname, filename in os.walk(data_path):\n",
    "    print(dirpath, dirname, len(filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be5b15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff25af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set random seet\n",
    "image_path_list = list(data_path.glob(\"*/*/*.jpg\"))\n",
    "image_path_list\n",
    "\n",
    "sample_path_list = random.sample(image_path_list, k=10)\n",
    "sample_path_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d79f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_image_in_grid(image_paths, grid_size=(4,3)):\n",
    "    num_images = len(image_paths)\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(12,12))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.axis('off')\n",
    "        if i < num_images:\n",
    "            image_path = image_paths[i]\n",
    "            image = mpimg.imread(image_path)\n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"Class: {image_paths[i].parent.stem} | Path {image_paths[i].stem}\", fontsize=10)\n",
    "        \n",
    "\n",
    "display_image_in_grid(sample_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def display_image_before_after_transform(image_paths, transform, grid_size=(10,2)):\n",
    "    num_images = len(image_paths)\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(10, 5*grid_size[0]))\n",
    "\n",
    "    for i, ax_row in enumerate(axes):\n",
    "        image_path = image_paths[i]\n",
    "        print(image_path)\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            # ax.set_title(f\"Row: {i} | Col: {j} | Index: {i*2+j}\")\n",
    "\n",
    "            if j == 0:                \n",
    "                image = mpimg.imread(image_path)\n",
    "                ax.set_title(f\"{image_path}\")\n",
    "                ax.imshow(image)\n",
    "            else:\n",
    "                image = Image.open(image_path)\n",
    "                transformed_image = transform(image).permute(1,2,0) # Convert (C x H x W) to (H x W x C)\n",
    "                ax.set_title(f\"Transformed\")\n",
    "                ax.imshow(transformed_image)        \n",
    "        \n",
    "\n",
    "display_image_before_after_transform(sample_path_list, image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00406dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_image_dir,\n",
    "                                 transform=image_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_image_dir,\n",
    "                                transform=image_transform)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c601955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = train_data.classes\n",
    "class_name_idx = train_data.class_to_idx\n",
    "\n",
    "print(class_name, class_name_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKER = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKER)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0d38c",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14655b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0,0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Send data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward Pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate Function Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer Zero Grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss Backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer Step\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Send data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward Pass\n",
    "        test_pred_logits = model(X)\n",
    "\n",
    "        # 2. Calculate Loss\n",
    "        loss = loss_fn(test_pred_logits, y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc += (test_pred_labels == y).sum().item() / len(test_pred_logits)\n",
    "\n",
    "    \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          device:torch.device,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int=5,\n",
    "          ):\n",
    "    \n",
    "    results = {\"train_loss\":[],\n",
    "                 \"train_acc\": [],\n",
    "                 \"test_loss\": [],\n",
    "                 \"test_acc\": []}\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn = loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32cd26",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a55591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def pred_and_plot_image(\n",
    "    model: torch.nn.Module,\n",
    "    class_names: List[str],\n",
    "    image_path: str,\n",
    "    image_size: Tuple[int, int] = (224, 224),\n",
    "    transform: torchvision.transforms = None,\n",
    "    device: torch.device = device,\n",
    "):\n",
    "\n",
    "\n",
    "    # Open image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    # Plot image with predicted label and probability\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(\n",
    "        f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\"\n",
    "    )\n",
    "    plt.axis(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_loss_acc(model_results):\n",
    "    print(model_results)\n",
    "\n",
    "    print(model_results['train_loss'])\n",
    "    print(range(len(model_results)))\n",
    "\n",
    "    num_epoch = range(1, len(model_results['train_loss'])+1)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(num_epoch, model_results['train_loss'], label=\"Train Loss\")\n",
    "    plt.plot(num_epoch, model_results['test_loss'], label =\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(num_epoch, model_results['train_acc'], label=\"Train Accuracy\")\n",
    "    plt.plot(num_epoch, model_results['test_acc'], label =\"Test Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab146a4b",
   "metadata": {},
   "source": [
    "# Model And Training\n",
    "\n",
    "#### https://www.kaggle.com/datasets/techsash/waste-classification-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b0a7e",
   "metadata": {},
   "source": [
    "### TinyVGG Architectire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fecfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "class TinyVGGModel0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_unit: int, output_shape:int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_unit,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_unit,\n",
    "                      out_channels=hidden_unit,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1,\n",
    "                         stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_unit,\n",
    "                      out_channels=hidden_unit,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_unit,\n",
    "                      out_channels=hidden_unit,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= hidden_unit * 56 * 56,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.conv_block1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d944b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGGModel0(input_shape=3,\n",
    "                        hidden_unit=10,\n",
    "                        output_shape=len(class_name)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "image_single, label_single = image_batch[0].unsqueeze(dim=0), label_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ca3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_single = model_0(image_single.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model_0 = TinyVGGModel0(input_shape=3,\n",
    "                        hidden_unit=10,\n",
    "                        output_shape=len(class_name)).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_0_results = train(model=model_0,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        device=device,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Total Training Time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382dd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_0.state_dict(), \"models/TinyVGGModel0.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss_acc(model_0_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_image(model=model_0, transform=image_transform, image_path=\"test_image.jpg\", device=device, class_names = class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e82b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_image(model=model_0, transform=image_transform, image_path=\"test_image_2.jpeg\", device=device, class_names = class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d07e8",
   "metadata": {},
   "source": [
    "### Efficient Architecture (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a486dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "efficient_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.299, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_image_dir,\n",
    "                                 transform=efficient_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_image_dir,\n",
    "                                transform=efficient_transform)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_WORKER = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKER)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT \n",
    "model_1 = torchvision.models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7735e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_1,\n",
    "        input_size=(20,3,224, 224),\n",
    "        col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings=[\"var_names\"]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Parameter except classification\n",
    "for param in model_1.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Manual Seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length\n",
    "output_shape = len(class_name)\n",
    "\n",
    "# Override classifier layer\n",
    "model_1.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280,\n",
    "                    out_features=output_shape,\n",
    "                    bias=True).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_1,\n",
    "        input_size=(20,3,224, 224),\n",
    "        col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings=[\"var_names\"]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8093c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96009db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "model_1_results = train(model=model_1,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      optimizer=optimizer,\n",
    "      loss_fn=loss_fn,\n",
    "      epochs=5,\n",
    "      device=device)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"[INFO] Total Training Time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss_acc(model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_1.state_dict(), \"models/EfficientModel1.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d21b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b80d1c4",
   "metadata": {},
   "source": [
    "### Efficient Model (Transfer Learning) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "efficient_augment_transform = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=42),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.299, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_before_after_transform(sample_path_list, efficient_augment_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_image_dir,\n",
    "                                 transform=efficient_augment_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_image_dir,\n",
    "                                transform=efficient_augment_transform)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_WORKER = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKER)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ea4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT \n",
    "model_2 = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Parameter except classification\n",
    "for param in model_2.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c224bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Manual Seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length\n",
    "output_shape = len(class_name)\n",
    "\n",
    "# Override classifier layer\n",
    "model_2.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280,\n",
    "                    out_features=output_shape,\n",
    "                    bias=True).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4989523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "model_2_results = train(model=model_2,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      optimizer=optimizer,\n",
    "      loss_fn=loss_fn,\n",
    "      epochs=5,\n",
    "      device=device)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"[INFO] Total Training Time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss_acc(model_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2.state_dict(), \"models/EfficientModelAugmented2.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31405f73",
   "metadata": {},
   "source": [
    "### ResNET50 Model (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd618288",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model_3 = torchvision.models.resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "efficient_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.299, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_image_dir,\n",
    "                                 transform=efficient_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_image_dir,\n",
    "                                transform=efficient_transform)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_WORKER = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKER)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4898255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_3,\n",
    "        input_size=(20,3,224, 224),\n",
    "        col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings=[\"var_names\"]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze Parameter except classification\n",
    "for param in model_3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd667cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Manual Seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length\n",
    "output_shape = len(class_name)\n",
    "\n",
    "# Override classifier layer\n",
    "model_3.fc = torch.nn.Linear(in_features=2048,\n",
    "                    out_features=output_shape,\n",
    "                    bias=True).to(device)\n",
    "\n",
    "\n",
    "model_3.fc.require_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ebbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_3,\n",
    "        input_size=(20,3,224, 224),\n",
    "        col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings=[\"var_names\"]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_3.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "model_3_results = train(model=model_3,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      optimizer=optimizer,\n",
    "      loss_fn=loss_fn,\n",
    "      epochs=30,\n",
    "      device=device)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"[INFO] Total Training Time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss_acc(model_results=model_3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_3.state_dict(), \"models/ResNET50Model3.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1af8a",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed995d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d433ae3",
   "metadata": {},
   "source": [
    "# Waste Multi Classification \n",
    "\n",
    "### Alumunium, Carton, E-Waste, Glass, Organic Waste, Paper and Cardboard, Plastics, Textile, Wood\n",
    "\n",
    "#### /DATASET_MULTI_CLASS\n",
    "\n",
    "https://storage.googleapis.com/kaggle-data-sets/3626433/6303652/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240229%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240229T062751Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=142da64904cfea122a9ac41d9b17e1267b464fa29828686d5b45a30b37021241d2485c79247d40ebdf2459bd54444948d9167cd2a9802fa6185d48138f7c33bb7799c74dacf58dd3cad26a560f18c05d6db20186dc1278483f8711a0ffdfa5d21b484ddcee4d9f3ec75ee78cc52f6d27003b26ab750d6f10cdeec1682e12abcf548a767ff8b9244f8e51adcc00a2ebc6c6c59389df8a7d6735f22f9d28f1328bbbb6834f973f723ac12524c3a114884e9c79ec85fed859501ea78d4d2c127bea34dd0526c53aed5413ee3a8dc64978261b15e67d8989d4a40816cc0f4e96d6ee96dfbff6376cf934f0b405fca24211b23f13dca9674b0834fb6db9fe201ab26a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbbe1b",
   "metadata": {},
   "source": [
    "## Split Folder Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "archive_path = \"archive/archive (3)/Waste Images\"\n",
    "target_path = \"DATASET_MULTI_CLASS\"\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(target_path, \"Train\")\n",
    "test_dir = os.path.join(target_path, \"Test\")\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for folder in os.listdir(archive_path):\n",
    "    # print(\"Class Name\", folder)\n",
    "    folder_path = os.path.join(archive_path, folder)\n",
    "    # print(\"Class Path\", folder_path)\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Renaming files according to the naming convention\n",
    "    for idx, file in enumerate(files):\n",
    "        name, ext = os.path.splitext(file)\n",
    "        new_name = f\"{folder} ({idx + 1}){ext}\"\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        new_img_path = os.path.join(folder_path, new_name)\n",
    "        # print(img_path, \"->\", new_img_path)\n",
    "        try:\n",
    "            if os.path.exists(img_path):\n",
    "                shutil.move(img_path, new_img_path)\n",
    "            else:\n",
    "                print(f\"Warning: File {img_path} not found.\")\n",
    "                print(file, '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(archive_path):\n",
    "    # print(\"Class Name\", folder)\n",
    "    folder_path = os.path.join(archive_path, folder)\n",
    "    # print(\"Class Path\", folder_path)\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    len_files = len(files)\n",
    "    len_train = int(0.8 * len_files)\n",
    "\n",
    "    # print(f\"All Files Len: {len_files} | Train Files: {len_train} | Test: {len_files - len_train}\")\n",
    "\n",
    "    train_files = random.sample(files, len_train)\n",
    "    test_files = [file for file in files if file not in train_files]\n",
    "\n",
    "    # print(\"Train Files\", train_files)\n",
    "    # print(\"Test Files\", test_files)\n",
    "\n",
    "    train_class_dir = os.path.join(train_dir, folder)\n",
    "    test_class_dir = os.path.join(test_dir, folder)\n",
    "\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for file in train_files:\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        shutil.copy(img_path, train_class_dir)\n",
    "        if len(img_path) > 50 + len(folder_path):\n",
    "            print(img_path)            \n",
    "\n",
    "    for file in test_files:\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        shutil.copy(img_path, test_class_dir)\n",
    "        if len(img_path) > 50 + len(folder_path):\n",
    "            print(img_path)              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79bd07",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b32ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a3a336",
   "metadata": {},
   "source": [
    "## Model And Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec09a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model_4 = torchvision.models.resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c42509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "data_path = Path(\"DATASET_MULTI_CLASS\")\n",
    "\n",
    "train_image_dir = data_path / \"TRAIN\"\n",
    "test_image_dir = data_path / \"TEST\"\n",
    "\n",
    "train_image_dir, test_image_dir\n",
    "\n",
    "\n",
    "resnet50_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.299, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_image_dir,\n",
    "                                 transform=resnet50_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_image_dir,\n",
    "                                transform=resnet50_transform)\n",
    "\n",
    "class_name = train_data.classes\n",
    "class_name_idx = train_data.class_to_idx\n",
    "\n",
    "print(class_name, class_name_idx)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_WORKER = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKER)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze Parameter except classification\n",
    "for param in model_4.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff97be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69368cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_name)\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_4,\n",
    "        input_size=(20,3,224, 224),\n",
    "        col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings=[\"var_names\"]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Manual Seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length\n",
    "output_shape = len(class_name)\n",
    "\n",
    "# Override classifier layer\n",
    "model_4.fc = torch.nn.Linear(in_features=2048,\n",
    "                    out_features=output_shape,\n",
    "                    bias=True).to(device)\n",
    "\n",
    "\n",
    "model_4.fc.require_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_4.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed20126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "model_4_results = train(model=model_4,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      optimizer=optimizer,\n",
    "      loss_fn=loss_fn,\n",
    "      epochs=9,\n",
    "      device=device)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"[INFO] Total Training Time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a35822",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_loss_acc(model_4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_4.state_dict(), \"models/MultiClassResNET50Model4.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee681d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_image(model=model_4, image_path=\"test_image_2.jpeg\", transform=resnet50_transform, class_names=class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5231f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e57fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
